{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random # 시드 고정을 위해\n",
    "import os # 시드 고정을 위해\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "from torch import Tensor,tensor\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch.nn import Module,Sequential\n",
    "\n",
    "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def reset_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "\n",
    "conn = pymysql.connect(host='127.0.0.1', user='wodus1530',\n",
    "                       password='dkvms7255', db='Zigzag')\n",
    "\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "sql_query = 'SELECT * FROM db'\n",
    "cursor.execute(sql_query)\n",
    "\n",
    "result = cursor.fetchall()\n",
    "column_names = [i[0] for i in cursor.description]\n",
    "\n",
    "\n",
    "db = pd.DataFrame(result, columns=column_names)\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_data_1 = pd.DataFrame(db[db['색감'] != 0]['리뷰'], columns=['리뷰']).reset_index(drop=True)\n",
    "color_data_1['target'] = 1\n",
    "\n",
    "color_data_2 = pd.DataFrame(db[db['색감'] == 0]['리뷰'], columns=['리뷰']).reset_index(drop=True)\n",
    "color_data_2['target'] = 0\n",
    "\n",
    "color_data = pd.concat([color_data_1, color_data_2], axis=0).reset_index(drop=True)\n",
    "color_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# SEED = 42\n",
    "# color_targets=color_data['target']\n",
    "\n",
    "# legacy, new, legacy_target, new_target = train_test_split(color_data, color_targets, train_size=0.8, test_size=0.2, random_state=SEED, shuffle=True)\n",
    "\n",
    "# len(legacy),len(new),len(legacy_target),len(new_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mecab import MeCab\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "filter=['NNG','MAG','EC','VA','VA+EF','VV+ETM','NNB+JKB','VCP+EC','VCP','MAG+JX','VCN']\n",
    "\n",
    "def tokenizer(data):\n",
    "    tokenizer = MeCab()\n",
    "    \n",
    "    list = []\n",
    "    \n",
    "    for text in tqdm(data[\"리뷰\"]):\n",
    "        prah = []  \n",
    "        lst = tokenizer.pos(text)  \n",
    "        for word, pos in lst:\n",
    "            if pos in filter:\n",
    "                prah.append(word)  \n",
    "        list.append(' '.join(prah))  \n",
    "    \n",
    "    return pd.DataFrame({'tokens':list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_tokenizer(data):\n",
    "    tokenizer = MeCab()\n",
    "    \n",
    "    list = []\n",
    "    \n",
    "    for text in tqdm(data):\n",
    "        prah = []  \n",
    "        lst = tokenizer.pos(text)  \n",
    "        for word, pos in lst:\n",
    "            if pos in filter:\n",
    "                prah.append(word)  \n",
    "        list.append(' '.join(prah))  \n",
    "    \n",
    "    return pd.DataFrame({'tokens':list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data=np.array([['이옷 너무 좋아요 특히 색감이 화면에 나온거랑 완전 똑같아요!'],\n",
    "                      ['보들보들 짱짱 여름에도 좋을듯!!']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_tokenizer(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_list=tokenizer(legacy)\n",
    "# test_list=tokenizer(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_list=tokenizer(color_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# legacy = pd.DataFrame({'tokens': train_list})\n",
    "# new = pd.DataFrame({'tokens': test_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# vectorizer = TfidfVectorizer(max_features=100)\n",
    "# legacy_tfidf = vectorizer.fit_transform(legacy[\"tokens\"])\n",
    "\n",
    "# new_tfidf=vectorizer.transform(new[\"tokens\"])\n",
    "\n",
    "# legacy_tfidf=legacy_tfidf.toarray()\n",
    "# new_tfidf=new_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=100)\n",
    "legacy_tfidf = vectorizer.fit_transform(DB_list[\"tokens\"])\n",
    "\n",
    "legacy_tfidf=legacy_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "legacy_tfidf = scaler.fit_transform(legacy_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legacy_df = pd.DataFrame(legacy_tfidf, columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "important_feature_indices = sorted_indices[sorted_feature_importances >= 1]\n",
    "legacy_tfidf_filtered = legacy_tfidf[:, important_feature_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legacy_df.iloc[:,important_feature_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False\n",
    "\n",
    "\n",
    "catboost_model = CatBoostClassifier(random_state=42, verbose=0)\n",
    "\n",
    "\n",
    "catboost_model.fit(legacy_tfidf, color_data['target'])\n",
    "\n",
    "\n",
    "feature_importances = catboost_model.feature_importances_\n",
    "\n",
    "feature_names = legacy_df.columns\n",
    "\n",
    "\n",
    "sorted_indices = np.argsort(feature_importances)[::-1]\n",
    "sorted_feature_importances = feature_importances[sorted_indices]\n",
    "sorted_feature_names = feature_names[sorted_indices]\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.barh(range(len(sorted_feature_importances)), sorted_feature_importances, align='center', alpha=0.7)\n",
    "plt.yticks(range(len(sorted_feature_importances)), sorted_feature_names)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importances (CatBoost)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "important_feature_indices = sorted_indices[sorted_feature_importances >= 1]\n",
    "legacy_tfidf_filtered = legacy_tfidf[:, important_feature_indices]\n",
    "\n",
    "X_train_filtered, X_test_filtered, y_train_filtered, y_test_filtered = train_test_split(legacy_tfidf_filtered, legacy_target, test_size=0.2, random_state=SEED)\n",
    "\n",
    "\n",
    "catboost_model_filtered = CatBoostClassifier(random_state=42, verbose=0)\n",
    "catboost_model_filtered.fit(X_train_filtered, y_train_filtered)\n",
    "\n",
    "\n",
    "accuracy_filtered = catboost_model_filtered.score(X_test_filtered, y_test_filtered)\n",
    "print(\"Accuracy on the filtered test set:\", accuracy_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_10_indices = sorted_indices[:10]\n",
    "\n",
    "legacy_tfidf_filtered = legacy_tfidf[:, top_10_indices]\n",
    "\n",
    "X_train_filtered, X_test_filtered, y_train_filtered, y_test_filtered = train_test_split(legacy_tfidf_filtered, legacy_target, test_size=0.2, random_state=SEED)\n",
    "\n",
    "catboost_model_filtered = CatBoostClassifier(random_state=42, verbose=0)\n",
    "catboost_model_filtered.fit(X_train_filtered, y_train_filtered)\n",
    "\n",
    "\n",
    "accuracy_filtered = catboost_model_filtered.score(X_test_filtered, y_test_filtered)\n",
    "print(\"Accuracy on the filtered test set using top 10 features:\", accuracy_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=catboost_model.predict(new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(pred,new_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list=tokenizer(color_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False\n",
    "\n",
    "\n",
    "catboost_model = CatBoostClassifier(random_state=42, verbose=0)\n",
    "\n",
    "\n",
    "catboost_model.fit(legacy_tfidf, color_data['target'])\n",
    "\n",
    "\n",
    "feature_importances = catboost_model.feature_importances_\n",
    "\n",
    "feature_names = legacy_df.columns\n",
    "\n",
    "\n",
    "sorted_indices = np.argsort(feature_importances)[::-1]\n",
    "sorted_feature_importances = feature_importances[sorted_indices]\n",
    "sorted_feature_names = feature_names[sorted_indices]\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.barh(range(len(sorted_feature_importances)), sorted_feature_importances, align='center', alpha=0.7)\n",
    "plt.yticks(range(len(sorted_feature_importances)), sorted_feature_names)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importances (CatBoost)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "important_feature_indices = sorted_indices[sorted_feature_importances >= 1]\n",
    "legacy_tfidf_filtered = legacy_tfidf[:, important_feature_indices]\n",
    "\n",
    "X_train_filtered, X_test_filtered, y_train_filtered, y_test_filtered = train_test_split(legacy_tfidf_filtered, color_data['target'] ,test_size=0.2, random_state=SEED)\n",
    "\n",
    "\n",
    "catboost_model_filtered = CatBoostClassifier(random_state=42, verbose=0)\n",
    "catboost_model_filtered.fit(X_train_filtered, y_train_filtered)\n",
    "\n",
    "\n",
    "accuracy_filtered = catboost_model_filtered.score(X_test_filtered, y_test_filtered)\n",
    "print(\"Accuracy on the filtered test set:\", accuracy_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=pd.DataFrame(['색감이너무 좋아요 화면이랑 똑같아요!'],columns=['리뷰'])\n",
    "\n",
    "sample_data=tokenizer(sample)\n",
    "\n",
    "sample_data['tokens']=sample_data['tokens'].apply(lambda x:' '.join(x))\n",
    "\n",
    "catboost_model_filtered.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
