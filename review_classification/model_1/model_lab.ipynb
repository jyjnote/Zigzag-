{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd0a6a4d-1cae-4a54-997c-471f21ff3e92",
   "metadata": {},
   "source": [
    "# 데이터 불러오기 및 학습 데이터와 테스트 데이터 분류 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d3da630-de40-4d0f-907b-71b7e81c8f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import os\n",
    "\n",
    "def reset_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c44018e-41a5-43c9-8de5-3807fb166448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기 \n",
    "\n",
    "train_ft = pd.read_excel('zigzag_clothes.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b1b3030-eaa8-4496-a3d6-012983f081a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 전처리 \n",
    "\n",
    "train_ft['리뷰'] = train_ft['리뷰'].str.replace('\\n','. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19d9fdf2-a10c-46ea-8554-7c4b3b721c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7193, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 당장 분석에 필요없는 컬럼 제거 \n",
    "\n",
    "drop_columns = ['중분류', '브랜드', '상품명', '가격', '리뷰수', '상품평점', '닉네임', '별점', '날짜', '키',\n",
    "       '몸무게', '상의사이즈', '선택옵션', '사이즈평가', '퀄리티평가', '색감평가']\n",
    "\n",
    "train_ft.drop(drop_columns,axis = 1,inplace = True)\n",
    "\n",
    "train_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea0259b4-7748-4f6c-8958-e15a81c128cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex) 기본 키워드의 경우에는 키워드별 존재 여부에 대한 모델에 적용하기 위해 -1을 1로 바꿔야 합니다. \n",
    "# 그렇게 되면 원본 키워드가 훼손되기 때문에 복사해서 따로 컬럼을 만들어줍니다. \n",
    "train_ft['색감_긍부정'] = train_ft['색감'].copy()\n",
    "train_ft['핏_긍부정'] = train_ft['핏'].copy()\n",
    "train_ft['재질_긍부정'] = train_ft['재질'].copy()\n",
    "train_ft['퀄리티_긍부정'] = train_ft['퀄리티'].copy()\n",
    "train_ft['제품상태_긍부정'] = train_ft['제품상태'].copy()\n",
    "train_ft['가격.1_긍부정'] = train_ft['가격.1'].copy()\n",
    "train_ft['두께_긍부정'] = train_ft['두께'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a8b918d-80c8-4ff2-84d6-711cbdfd51d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [   0    1    2 ... 7189 7191 7192] TEST: [   6    7   19 ... 7183 7188 7190]\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터와 테스트 데이터 분류 작업 \n",
    "# y정답데이터를 기준으로 키워드별로 층화추출이 행해집니다. \n",
    "\n",
    "x,y = train_ft[['리뷰','색감_긍부정','핏_긍부정','재질_긍부정','퀄리티_긍부정','제품상태_긍부정','가격.1_긍부정','두께_긍부정']].to_numpy(), train_ft[['색감', '핏', '재질', '퀄리티', '제품상태', '가격.1', '두께']].replace(-1,1).to_numpy()\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "msss = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in msss.split(x, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15f39235-54b5-42ac-b763-d10e808b0f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종적인 학습 데이터와 테스트 데이터가 만들어집니다. \n",
    "\n",
    "tmp_1 = pd.DataFrame(x_train,columns = ['리뷰','색감_긍부정','핏_긍부정','재질_긍부정','퀄리티_긍부정','제품상태_긍부정','가격.1_긍부정','두께_긍부정'])\n",
    "tmp_2 = pd.DataFrame(y_train,columns = ['색감', '핏', '재질', '퀄리티', '제품상태', '가격.1', '두께'])\n",
    "\n",
    "train_ft = pd.concat([tmp_1,tmp_2],axis = 1)\n",
    "\n",
    "tmp_1 = pd.DataFrame(x_test,columns = ['리뷰','색감_긍부정','핏_긍부정','재질_긍부정','퀄리티_긍부정','제품상태_긍부정','가격.1_긍부정','두께_긍부정'])\n",
    "tmp_2 = pd.DataFrame(y_test,columns = ['색감', '핏', '재질', '퀄리티', '제품상태', '가격.1', '두께'])\n",
    "\n",
    "test_ft = pd.concat([tmp_1,tmp_2],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ad584c4-3b08-4a5d-be83-050415cc10c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5754, 15), (1439, 15))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft.shape,test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47fd54de-bf25-4ca9-85c5-613008703173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5754, 8), (1439, 8))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 키워드별 긍부정을 예측할 때 사용하는 데이터 셋\n",
    "\n",
    "train_tmp = train_ft.iloc[:,:8].copy()\n",
    "test_tmp = test_ft.iloc[:,:8].copy()\n",
    "\n",
    "train_tmp.shape,test_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad15c5f2-1b8b-4fb7-bc1a-7431595080e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5754, 8), (1439, 8))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 키워드 존재 여부를 판단하는 모델을 위한 데이터 셋\n",
    "\n",
    "train_ft = train_ft.drop(train_ft.columns[1:8], axis=1).copy()\n",
    "test_ft = test_ft.drop(test_ft.columns[1:8], axis=1).copy()\n",
    "\n",
    "train_ft.shape,test_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e21313e7-1882-417d-b175-122172fe7e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5754,), (1439,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사전학습 모델에서 임베딩 작업이 행해지기 때문에 numpy의 형태로 전달해야 합니다. \n",
    "\n",
    "train_arr = train_ft['리뷰'].to_numpy()\n",
    "test_arr = test_ft['리뷰'].to_numpy()\n",
    "\n",
    "train_arr.shape,test_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "548e0c8b-19a9-4346-8b1f-2065579f82ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5754, 7), (1439, 7))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이항분류 문제의 경우에는 이차원으로 전달해야 하는데 이미 2차원의 형태이기 때문에 numpy의 형태로만 전달을 해줍니다. \n",
    "\n",
    "target = train_ft.iloc[:,1:].to_numpy().copy()\n",
    "target_test = test_ft.iloc[:,1:].to_numpy().copy()\n",
    "\n",
    "target.shape,target_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eeace1-5b51-4d29-8901-91fe0a867fa4",
   "metadata": {},
   "source": [
    "# 사전학습 모델 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e1e50f8-42a3-42b2-ad80-87b76576d020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'BM-K/KoDiffCSE-RoBERTa'\n",
    "# TF-IDF로 단어문서 행렬을 정리한 후 decomp를 통한 주제분석 피처를 추가했을 경우 점수 75 (한번의 Fold에서)\n",
    "# 오직 사전학습만 적용했을 경우 점수 73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9be2550d-bdee-42d4-909e-c04091e2459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'amberoad/bert-multilingual-passage-reranking-msmarco'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40160e94-b233-48b3-a2b0-9693183d7ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'team-lucid/deberta-v3-base-korean'\n",
    "# 순수하게 이것만 이용했을 때는 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce423425-dc91-4038-ae88-8cc334a063bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'smilegate-ai/kor_unsmile'\n",
    "# 순수하게 이것만 이용했을 때 74\n",
    "# 단어문서 행렬을 붙이면 73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ade00e4f-6aca-4d7e-ae64-2efa9dc6995f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'BM-K/KoSimCSE-roberta'\n",
    "# 순수하게 이것만 이용했을 때 75가 나온다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32c3d2b5-9a88-431d-ba39-4a5ed052111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'minalang/KoDSE-bert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7bfd43d-ebd1-43cb-ad54-905d4b462ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'kykim/bert-kor-base'\n",
    "# 기본으로 적용해도 76\n",
    "# TF-IDF로 단어문서 행렬을 정리한 후 decomp를 통한 주제분석 피처를 추가했을 경우 점수 76 (한번의 Fold에서)\n",
    "# cat decomp, RNN, CNN의 경우에는 모델 자체가 무거워지는 현상이 발생함, 점수 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ff0c8c8-50fb-451d-8a64-7fb040ade087",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93e756ea-1208-499a-a6b6-266de999fca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab01/.local/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 만일 padding의 길이를 지정해주고 싶다면?\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length = 512)\n",
    "# tokenizer.model_max_length로 padding의 길이도 한번 확인보면 좋을 듯 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eba9c9-ff66-43c0-b114-63542b78cb8a",
   "metadata": {},
   "source": [
    "# 사전학습만을 이용하여 학습 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f98de59f-277e-4d77-8c9d-ba20e89b4e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenizer, x, y=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {}\n",
    "        item[\"x\"] = self.get_tokenizer(self.x[idx])\n",
    "        if self.y is not None:\n",
    "            item[\"y\"] = torch.Tensor(self.y[idx])\n",
    "        return item\n",
    "    def get_tokenizer(self, text):\n",
    "        x = self.tokenizer(text, padding=\"max_length\", truncation=True)\n",
    "        for k, v in x.items():\n",
    "            x[k] = torch.tensor(v)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7480823b-52c3-407d-b109-74c6ac41d570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': {'input_ids': tensor([[    2,  2059, 18764,  ...,     0,     0,     0],\n",
       "         [    2,  7386, 18392,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]])},\n",
       " 'y': tensor([[0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 1.]])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = ReviewDataset(tokenizer, train_arr, target)\n",
    "dl = torch.utils.data.DataLoader(dt, batch_size=2, shuffle=False)\n",
    "batch = next(iter(dl))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ad4fcdc-e417-42d8-8b4d-2682dba659fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        self.pre_model = AutoModel.from_pretrained(model_name)\n",
    "        self.fc_out = torch.nn.Linear( self.pre_model.config.hidden_size, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pre_model(**x)\n",
    "        # x[0]: 모든 시점의 히든출력 batch, seq, features\n",
    "        # x[1]: CLS 토큰의 히든출력 batch, features\n",
    "        return self.fc_out(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77b0e731-6af3-4d4e-9cd1-bea3e9ded989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0426, -0.3442,  0.0453, -0.1306, -0.0273, -0.0229,  0.3785],\n",
       "        [ 0.5101,  0.4435,  0.0894,  0.0829, -0.0481, -0.1151,  0.4884]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net(model_name)\n",
    "model(batch[\"x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4806cf31-cfbf-4440-b2c3-4fa7045f541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, device):\n",
    "    epoch_loss = 0\n",
    "    model.train() # 학습 모드\n",
    "    for batch in tqdm(dataloader):\n",
    "        pred = model( batch[\"x\"].to(device) )\n",
    "        loss = loss_fn( pred, batch[\"y\"].to(device) )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(dataloader)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2972463-ae24-465d-9063-5ac782812173",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_loop(dataloader, model, loss_fn, device):\n",
    "    epoch_loss = 0\n",
    "    pred_list = []\n",
    "    act_func = torch.nn.Sigmoid()\n",
    "    model.eval() # 평가 모드\n",
    "    for batch in tqdm(dataloader):\n",
    "        pred = model( batch[\"x\"].to(device) )\n",
    "        if batch.get(\"y\") is not None:\n",
    "            loss = loss_fn( pred, batch[\"y\"].to(device) )\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        pred = act_func(pred) # logit 값을 확률로 변환\n",
    "        pred = pred.to(\"cpu\").numpy() # cpu 이동후 ndarray 로변환\n",
    "        pred_list.append(pred)\n",
    "\n",
    "    epoch_loss /= len(dataloader)\n",
    "    pred = np.concatenate(pred_list)\n",
    "    return epoch_loss, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f601e1f-ca25-4713-aa11-29aa38ab8de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "n_splits = 5\n",
    "cv = KFold(n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "batch_size = 8 # 배치 사이즈\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss() # 손실 객체\n",
    "epochs = 100 # 최대 가능한 에폭수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0de6f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_holdout = False\n",
    "reset_seeds(42) # 재현을 위해 시드고정\n",
    "best_score_list = []\n",
    "for i, (tri, vai) in enumerate( cv.split(train_arr) ):\n",
    "    # 학습용 데이터로더 객체\n",
    "    train_dt = ReviewDataset(tokenizer, train_arr[tri], target[tri])\n",
    "    train_dl = torch.utils.data.DataLoader(train_dt, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # 검증용 데이터로더 객체\n",
    "    valid_dt = ReviewDataset(tokenizer, train_arr[vai], target[vai])\n",
    "    valid_dl = torch.utils.data.DataLoader(valid_dt, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # 모델 객체와 옵티마이저 객체 생성\n",
    "    model = Net(model_name).to(device)\n",
    "    optimizer = torch.optim.Adam( model.parameters(), lr=2e-5 )\n",
    "\n",
    "    best_score = 0 # 현재 최고 점수\n",
    "    patience = 0 # 조기 종료 조건을 주기 위한 변수\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_loop(train_dl, model, loss_fn, optimizer, device)\n",
    "        valid_loss, pred = test_loop(valid_dl, model, loss_fn, device)\n",
    "\n",
    "        pred = (pred > 0.5).astype(int) # 이진분류 문제에서 클래스 번호 결정\n",
    "        score = f1_score(target[vai], pred,average = None).mean()\n",
    "\n",
    "        print(train_loss, valid_loss, score)\n",
    "        if score > best_score:\n",
    "            best_score = score # 최고 점수 업데이트\n",
    "            patience = 0\n",
    "            torch.save(model.state_dict(), f\"model_{i}.pth\") # 최고 점수 모델 가중치 저장\n",
    "\n",
    "        patience += 1\n",
    "        if patience == 5:\n",
    "            break\n",
    "\n",
    "    print(f\"{i}번째 폴드 최고 정확도: {best_score}\")\n",
    "    best_score_list.append(best_score)\n",
    "\n",
    "    if is_holdout:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198357f7-3f88-4210-b9cd-3e4d286a049a",
   "metadata": {},
   "source": [
    "# 테스트 데이터 예측 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6304dd7a-df34-442f-9736-24151379d346",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dt = ReviewDataset(tokenizer,test_arr)\n",
    "test_dl = torch.utils.data.DataLoader(test_dt, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2631654-2baa-4c74-93e1-e391c079ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "for i in range(n_splits):\n",
    "    model = Net(model_name).to(device)\n",
    "    state_dict = torch.load(f\"model_{i}.pth\")\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    _, pred = test_loop(test_dl, model, loss_fn, device)\n",
    "\n",
    "    pred_list.append(pred)\n",
    "    if is_holdout:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dec651-4e25-439a-9cfe-0ba39f3cad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.mean(pred_list, axis=0)\n",
    "pred = (pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bc611a-70a5-477f-8f26-49f0e6680c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = f1_score(target_test, pred,average = 'macro')\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d569b0-5d8c-4e90-a30e-8c8c786a216f",
   "metadata": {},
   "source": [
    "# 만일 사전 학습 모델의 히든 출력에 cls토큰이 없다면 ? last_hidden_cell만 존재하는 경우에는?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19818030-f9b2-46fe-86da-312c6cf9cf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenizer, x, y=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {}\n",
    "        item[\"x\"] = self.get_tokenizer(self.x[idx])\n",
    "        if self.y is not None:\n",
    "            item[\"y\"] = torch.Tensor(self.y[idx])\n",
    "        return item\n",
    "    def get_tokenizer(self, text):\n",
    "        x = self.tokenizer(text, padding=\"max_length\", truncation=True)\n",
    "        for k, v in x.items():\n",
    "            x[k] = torch.tensor(v)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4ad01b-b55a-4a73-968d-2670eef854c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = ReviewDataset(tokenizer, train_arr, target)\n",
    "dl = torch.utils.data.DataLoader(dt, batch_size=2, shuffle=False)\n",
    "batch = next(iter(dl))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510cee2a-d868-4949-ac58-c9125dbc876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        self.pre_model = AutoModel.from_pretrained(model_name)\n",
    "        self.fc_out = torch.nn.Linear( self.pre_model.config.hidden_size, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pre_model(**x)\n",
    "        # x['last_hidden_state']: 모든 시점의 히든출력 batch, seq, feature\n",
    "        x = x['last_hidden_state']\n",
    "        return self.fc_out(x[:,0])\n",
    "        # 첫 번째 sequence의 batch,feature를 뽑아줍니다. \n",
    "        # 그러면 cls토큰과 똑같이 batch,feature차원으로 변경됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c6074b-dd60-4cb0-8d11-08b2c8a593a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(model_name)\n",
    "model(batch[\"x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824ccc4c-72a3-4e64-9e78-6d3d53b6142c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, device):\n",
    "    epoch_loss = 0\n",
    "    model.train() # 학습 모드\n",
    "    for batch in tqdm(dataloader):\n",
    "        pred = model( batch[\"x\"].to(device) )\n",
    "        loss = loss_fn( pred, batch[\"y\"].to(device) )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(dataloader)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9da36db-3dfc-4bc3-af02-1e4e32c0c13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_loop(dataloader, model, loss_fn, device):\n",
    "    epoch_loss = 0\n",
    "    pred_list = []\n",
    "    act_func = torch.nn.Sigmoid()\n",
    "    model.eval() # 평가 모드\n",
    "    for batch in tqdm(dataloader):\n",
    "        pred = model( batch[\"x\"].to(device) )\n",
    "        if batch.get(\"y\") is not None:\n",
    "            loss = loss_fn( pred, batch[\"y\"].to(device) )\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        pred = act_func(pred) # logit 값을 확률로 변환\n",
    "        pred = pred.to(\"cpu\").numpy() # cpu 이동후 ndarray 로변환\n",
    "        pred_list.append(pred)\n",
    "\n",
    "    epoch_loss /= len(dataloader)\n",
    "    pred = np.concatenate(pred_list)\n",
    "    return epoch_loss, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989ef8ff-20bb-4018-8c0d-f398479a5142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "n_splits = 5\n",
    "cv = KFold(n_splits, shuffle=True, random_state=SEED)\n",
    "\n",
    "batch_size = 8 # 배치 사이즈\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss() # 손실 객체\n",
    "epochs = 100 # 최대 가능한 에폭수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9220940c-58c5-4ebd-bc39-555e9edb1414",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_holdout = False\n",
    "reset_seeds(42) # 재현을 위해 시드고정\n",
    "best_score_list = []\n",
    "for i, (tri, vai) in enumerate( cv.split(train_arr) ):\n",
    "    # 학습용 데이터로더 객체\n",
    "    train_dt = ReviewDataset(tokenizer, train_arr[tri], target[tri])\n",
    "    train_dl = torch.utils.data.DataLoader(train_dt, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # 검증용 데이터로더 객체\n",
    "    valid_dt = ReviewDataset(tokenizer, train_arr[vai], target[vai])\n",
    "    valid_dl = torch.utils.data.DataLoader(valid_dt, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # 모델 객체와 옵티마이저 객체 생성\n",
    "    model = Net(model_name).to(device)\n",
    "    optimizer = torch.optim.Adam( model.parameters(), lr=2e-5 )\n",
    "\n",
    "    best_score = 0 # 현재 최고 점수\n",
    "    patience = 0 # 조기 종료 조건을 주기 위한 변수\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_loop(train_dl, model, loss_fn, optimizer, device)\n",
    "        valid_loss, pred = test_loop(valid_dl, model, loss_fn, device)\n",
    "\n",
    "        pred = (pred > 0.5).astype(int) # 이진분류 문제에서 클래스 번호 결정\n",
    "        score = f1_score(target[vai], pred,average = None).mean()\n",
    "\n",
    "        print(train_loss, valid_loss, score)\n",
    "        if score > best_score:\n",
    "            best_score = score # 최고 점수 업데이트\n",
    "            patience = 0\n",
    "            torch.save(model.state_dict(), f\"model_{i}.pth\") # 최고 점수 모델 가중치 저장\n",
    "\n",
    "        patience += 1\n",
    "        if patience == 5:\n",
    "            break\n",
    "\n",
    "    print(f\"{i}번째 폴드 최고 정확도: {best_score}\")\n",
    "    best_score_list.append(best_score)\n",
    "\n",
    "    if is_holdout:\n",
    "        break\n",
    "\n",
    "# 테스트 데이터에 대한 예측은 위와 동일하게 실행시킵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28ee930",
   "metadata": {},
   "source": [
    "# 단어 문서 행렬 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7a1988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa65e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ad1b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.fit(train_tmp[\"리뷰\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceb1056",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tdm = vectorizer.transform(train_tmp[\"리뷰\"])\n",
    "test_tdm = vectorizer.transform(test_tmp[\"리뷰\"])\n",
    "train_tdm.shape, test_tdm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906b5953",
   "metadata": {},
   "source": [
    "# 차원 축소 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e8ace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED  = 42\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "decomp = TruncatedSVD(1024, random_state=SEED)\n",
    "decomp.fit(train_tdm)\n",
    "\n",
    "train_tdm = decomp.transform(train_tdm)\n",
    "test_tdm = decomp.transform(test_tdm)\n",
    "\n",
    "train_tdm.shape, test_tdm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eb529b",
   "metadata": {},
   "source": [
    "# 사전학습 + 단어 문서 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d967879",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenizer,x_tdm,x, y=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.x_tdm = x_tdm # 단어문서행렬 \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.x_tdm)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {}\n",
    "        item['x_tdm'] = torch.Tensor(self.x_tdm[idx])\n",
    "        item[\"x\"] = self.get_tokenizer(self.x[idx])\n",
    "        if self.y is not None:\n",
    "            item[\"y\"] = torch.Tensor(self.y[idx])\n",
    "        return item\n",
    "    def get_tokenizer(self, text):\n",
    "        x = self.tokenizer(text, truncation = True, padding = 'max_length')\n",
    "        for k, v in x.items():\n",
    "            x[k] = torch.tensor(v)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005b67f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = ReviewDataset(tokenizer, train_tdm, train_arr, target)\n",
    "dl = torch.utils.data.DataLoader(dt, batch_size=2, shuffle=False)\n",
    "batch = next(iter(dl))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f48d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        self.pre_model = AutoModel.from_pretrained(model_name)\n",
    "        self.fc_out = torch.nn.Linear( self.pre_model.config.hidden_size  + 1024, 7)\n",
    "\n",
    "    def forward(self, x_tdm, x):\n",
    "        x = self.pre_model(**x) \n",
    "        return self.fc_out(torch.cat([x_tdm,x[1]],dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a176d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(model_name)\n",
    "model(batch[\"x_tdm\"],batch['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f43b5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, device):\n",
    "    epoch_loss = 0\n",
    "    model.train() # 학습 모드\n",
    "    for batch in tqdm(dataloader):\n",
    "        pred = model( batch[\"x_tdm\"].to(device),batch[\"x\"].to(device) )\n",
    "        loss = loss_fn( pred, batch[\"y\"].to(device) )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(dataloader)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3035661",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_loop(dataloader, model, loss_fn, device):\n",
    "    epoch_loss = 0\n",
    "    pred_list = []\n",
    "    act_func = torch.nn.Sigmoid()\n",
    "    model.eval() # 평가 모드\n",
    "    for batch in tqdm(dataloader):\n",
    "        pred = model( batch[\"x_tdm\"].to(device),batch[\"x\"].to(device) )\n",
    "        if batch.get(\"y\") is not None:\n",
    "            loss = loss_fn( pred, batch[\"y\"].to(device) )\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        pred = act_func(pred) # logit 값을 확률로 변환\n",
    "        pred = pred.to(\"cpu\").numpy() # cpu 이동후 ndarray 로변환\n",
    "        pred_list.append(pred)\n",
    "\n",
    "    epoch_loss /= len(dataloader)\n",
    "    pred = np.concatenate(pred_list)\n",
    "    return epoch_loss, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aedd08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "n_splits = 5\n",
    "cv = KFold(n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "batch_size = 16 # 배치 사이즈\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss() # 손실 객체\n",
    "epochs = 100 # 최대 가능한 에폭수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014f9700",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_holdout = True\n",
    "reset_seeds(42) # 재현을 위해 시드고정\n",
    "best_score_list = []\n",
    "for i, (tri, vai) in enumerate( cv.split(train_arr) ):\n",
    "    # 학습용 데이터로더 객체\n",
    "    train_dt = ReviewDataset(tokenizer, train_tdm[tri],train_arr[tri], target[tri])\n",
    "    train_dl = torch.utils.data.DataLoader(train_dt, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # 검증용 데이터로더 객체\n",
    "    valid_dt = ReviewDataset(tokenizer, train_tdm[vai],train_arr[vai], target[vai])\n",
    "    valid_dl = torch.utils.data.DataLoader(valid_dt, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # 모델 객체와 옵티마이저 객체 생성\n",
    "    model = Net(model_name).to(device)\n",
    "    optimizer = torch.optim.Adam( model.parameters(),lr=2e-5)\n",
    "\n",
    "    best_score = 0 # 현재 최고 점수\n",
    "    patience = 0 # 조기 종료 조건을 주기 위한 변수\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_loop(train_dl, model, loss_fn, optimizer, device)\n",
    "        valid_loss, pred = test_loop(valid_dl, model, loss_fn, device)\n",
    "\n",
    "        pred = (pred > 0.5).astype(int) # 이진분류 문제에서 클래스 번호 결정\n",
    "        score = f1_score(target[vai], pred,average = None).mean()\n",
    "\n",
    "        print(train_loss, valid_loss, score)\n",
    "        if score > best_score:\n",
    "            best_score = score # 최고 점수 업데이트\n",
    "            patience = 0\n",
    "            torch.save(model.state_dict(), f\"model_{i}.pth\") # 최고 점수 모델 가중치 저장\n",
    "\n",
    "        patience += 1\n",
    "        if patience == 5:\n",
    "            break\n",
    "\n",
    "    print(f\"{i}번째 폴드 최고 정확도: {best_score}\")\n",
    "    best_score_list.append(best_score)\n",
    "\n",
    "    if is_holdout:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f53949",
   "metadata": {},
   "source": [
    "# 사전학습 모델 + CNN + RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaf6b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델이 너무 무거워 짐\n",
    " class Net(torch.nn.Module):\n",
    "     def __init__(self, model_name):\n",
    "         super().__init__()\n",
    "         self.pre_# model = AutoModel.from_pretrained(model_name)\n",
    "         self.conv1d_block = torch.nn.Sequential(\n",
    "             torch.nn.Conv1d(self.pre_model.config.hidden_size,self.pre_model.config.hidden_size*2,3),\n",
    "             torch.nn.BatchNorm1d(self.pre_model.config.hidden_size * 2),\n",
    "             torch.nn.ReLU(),\n",
    "             torch.nn.AvgPool1d(2),\n",
    " \n",
    "             torch.nn.Conv1d(self.pre_model.config.hidden_size * 2, self.pre_model.config.hidden_size * 4,3),\n",
    "             torch.nn.BatchNorm1d(self.pre_model.config.hidden_size * 4),\n",
    "             torch.nn.ReLU(),\n",
    "             torch.nn.AvgPool1d(2),\n",
    " \n",
    "             # torch.nn.AdaptiveMaxPool1d(1),\n",
    "             # torch.nn.Flatten(),\n",
    "             torch.nn.Dropout(0.2)\n",
    "         )\n",
    "         self.rnn_layer = torch.nn.GRU(self.pre_model.config.hidden_size * 4,\n",
    "                                        self.pre_model.config.hidden_size * 8,\n",
    "                                        batch_first = True,\n",
    "                                        bidirectional = True)\n",
    "         self.fc_out = torch.nn.Linear( self.pre_model.config.hidden_size * 16 + 1024, 7)\n",
    " \n",
    "     def forward(self, x_tdm, x):\n",
    "         x = self.pre_model(**x)\n",
    "         x = x[0].permute(0,2,1) # batch,feature,sequence\n",
    "         x = self.conv1d_block(x) # batch,feature,sequence\n",
    "         x = x.permute(0,2,1) # batch,sequence,feature\n",
    "         _, hn= self.rnn_layer(x) # nlayer, batch, features\n",
    "         x = hn.permute(1,0,2) # batch,nlayer,features\n",
    "         x = x.flatten(1) # batch,nlayer x features\n",
    "         # x[0]: 모든 시점의 히든출력 batch, seq, features\n",
    "         # x[1]: CLS 토큰의 히든출력 batch, features\n",
    "         return self.fc_out(torch.cat([x_tdm,x],dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cd9cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, device):\n",
    "    epoch_loss = 0\n",
    "    model.train() # 학습 모드\n",
    "    for batch in tqdm(dataloader):\n",
    "        pred = model( batch[\"x_tdm\"].to(device),batch[\"x\"].to(device) )\n",
    "        loss = loss_fn( pred, batch[\"y\"].to(device) )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(dataloader)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05b71db",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_loop(dataloader, model, loss_fn, device):\n",
    "    epoch_loss = 0\n",
    "    pred_list = []\n",
    "    act_func = torch.nn.Sigmoid()\n",
    "    model.eval() # 평가 모드\n",
    "    for batch in tqdm(dataloader):\n",
    "        pred = model( batch[\"x_tdm\"].to(device),batch[\"x\"].to(device) )\n",
    "        if batch.get(\"y\") is not None:\n",
    "            loss = loss_fn( pred, batch[\"y\"].to(device) )\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        pred = act_func(pred) # logit 값을 확률로 변환\n",
    "        pred = pred.to(\"cpu\").numpy() # cpu 이동후 ndarray 로변환\n",
    "        pred_list.append(pred)\n",
    "\n",
    "    epoch_loss /= len(dataloader)\n",
    "    pred = np.concatenate(pred_list)\n",
    "    return epoch_loss, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581f3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "n_splits = 5\n",
    "cv = KFold(n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "batch_size = 16 # 배치 사이즈\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss() # 손실 객체\n",
    "epochs = 100 # 최대 가능한 에폭수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62814a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_holdout = True\n",
    "reset_seeds(42) # 재현을 위해 시드고정\n",
    "best_score_list = []\n",
    "for i, (tri, vai) in enumerate( cv.split(train_arr) ):\n",
    "    # 학습용 데이터로더 객체\n",
    "    train_dt = ReviewDataset(tokenizer, train_tdm[tri],train_arr[tri], target[tri])\n",
    "    train_dl = torch.utils.data.DataLoader(train_dt, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # 검증용 데이터로더 객체\n",
    "    valid_dt = ReviewDataset(tokenizer, train_tdm[vai],train_arr[vai], target[vai])\n",
    "    valid_dl = torch.utils.data.DataLoader(valid_dt, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # 모델 객체와 옵티마이저 객체 생성\n",
    "    model = Net(model_name).to(device)\n",
    "    optimizer = torch.optim.Adam( model.parameters(),lr=2e-5)\n",
    "\n",
    "    best_score = 0 # 현재 최고 점수\n",
    "    patience = 0 # 조기 종료 조건을 주기 위한 변수\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_loop(train_dl, model, loss_fn, optimizer, device)\n",
    "        valid_loss, pred = test_loop(valid_dl, model, loss_fn, device)\n",
    "\n",
    "        pred = (pred > 0.5).astype(int) # 이진분류 문제에서 클래스 번호 결정\n",
    "        score = f1_score(target[vai], pred,average = None).mean()\n",
    "\n",
    "        print(train_loss, valid_loss, score)\n",
    "        if score > best_score:\n",
    "            best_score = score # 최고 점수 업데이트\n",
    "            patience = 0\n",
    "            torch.save(model.state_dict(), f\"model_{i}.pth\") # 최고 점수 모델 가중치 저장\n",
    "\n",
    "        patience += 1\n",
    "        if patience == 5:\n",
    "            break\n",
    "\n",
    "    print(f\"{i}번째 폴드 최고 정확도: {best_score}\")\n",
    "    best_score_list.append(best_score)\n",
    "\n",
    "    if is_holdout:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c14bd0a",
   "metadata": {},
   "source": [
    "# 사전학습 모델 + 단어 문서 행렬 (cls token이 존재하지 않는 경우)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066d5f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        self.pre_model = AutoModel.from_pretrained(model_name)\n",
    "      #  self.conv1d_block = torch.nn.Sequential(\n",
    "      #      torch.nn.AdaptiveMaxPool1d(1),\n",
    "      #      # batch,feature,1\n",
    "      #      torch.nn.Flatten(),\n",
    "      #      # batch,feature\n",
    "      #      torch.nn.Dropout(0.2)\n",
    "      #  )\n",
    "        self.fc_out = torch.nn.Linear( self.pre_model.config.hidden_size  + 1024, 7)\n",
    "\n",
    "    def forward(self, x_tdm, x):\n",
    "        x = self.pre_model(**x)['last_hidden_state']\n",
    "        x = x.permute(0,2,1)\n",
    "        # batch,sequence,feature = > batch,feature,sequence로 바꿔준다. \n",
    "        x = self.conv1d_block(x)\n",
    "        # batch,feature\n",
    "        return self.fc_out(torch.cat([x_tdm,x],dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85d56f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(model_name)\n",
    "model(batch[\"x_tdm\"],batch['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded0a496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, device):\n",
    "    epoch_loss = 0\n",
    "    model.train() # 학습 모드\n",
    "    for batch in tqdm(dataloader):\n",
    "        pred = model( batch[\"x_tdm\"].to(device),batch[\"x\"].to(device) )\n",
    "        loss = loss_fn( pred, batch[\"y\"].to(device) )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(dataloader)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7c492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "n_splits = 5\n",
    "cv = KFold(n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "batch_size = 8 # 배치 사이즈\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss() # 손실 객체\n",
    "epochs = 100 # 최대 가능한 에폭수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664b2f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_holdout = True\n",
    "reset_seeds(42) # 재현을 위해 시드고정\n",
    "best_score_list = []\n",
    "for i, (tri, vai) in enumerate( cv.split(train_arr) ):\n",
    "    # 학습용 데이터로더 객체\n",
    "    train_dt = ReviewDataset(tokenizer, train_tdm[tri],train_arr[tri], target[tri])\n",
    "    train_dl = torch.utils.data.DataLoader(train_dt, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # 검증용 데이터로더 객체\n",
    "    valid_dt = ReviewDataset(tokenizer, train_tdm[vai],train_arr[vai], target[vai])\n",
    "    valid_dl = torch.utils.data.DataLoader(valid_dt, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # 모델 객체와 옵티마이저 객체 생성\n",
    "    model = Net(model_name).to(device)\n",
    "    optimizer = torch.optim.Adam( model.parameters(),lr=2e-5)\n",
    "\n",
    "    best_score = 0 # 현재 최고 점수\n",
    "    patience = 0 # 조기 종료 조건을 주기 위한 변수\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_loop(train_dl, model, loss_fn, optimizer, device)\n",
    "        valid_loss, pred = test_loop(valid_dl, model, loss_fn, device)\n",
    "\n",
    "        pred = (pred > 0.5).astype(int) # 이진분류 문제에서 클래스 번호 결정\n",
    "        score = f1_score(target[vai], pred,average = None).mean()\n",
    "\n",
    "        print(train_loss, valid_loss, score)\n",
    "        if score > best_score:\n",
    "            best_score = score # 최고 점수 업데이트\n",
    "            patience = 0\n",
    "            torch.save(model.state_dict(), f\"model_{i}.pth\") # 최고 점수 모델 가중치 저장\n",
    "\n",
    "        patience += 1\n",
    "        if patience == 5:\n",
    "            break\n",
    "\n",
    "    print(f\"{i}번째 폴드 최고 정확도: {best_score}\")\n",
    "    best_score_list.append(best_score)\n",
    "\n",
    "    if is_holdout:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
