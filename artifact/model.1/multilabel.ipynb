{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2623a10e-ca9d-4486-87ea-55c1b87d5ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import os\n",
    "\n",
    "def reset_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "SEED=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5052ede5-7591-4b7b-8746-7be6ad1456c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기 \n",
    "\n",
    "train_ft = pd.read_excel('zigzag_clothes.xlsx')\n",
    "\n",
    "train_ft['리뷰'] = train_ft['리뷰'].str.replace('\\n','. ')\n",
    "# 당장 분석에 필요없는 컬럼 제거 \n",
    "\n",
    "drop_columns = ['중분류', '브랜드', '상품명', '가격', '리뷰수', '상품평점', '닉네임', '별점', '날짜', '키',\n",
    "       '몸무게', '상의사이즈', '선택옵션', '사이즈평가', '퀄리티평가', '색감평가']\n",
    "\n",
    "train_ft.drop(drop_columns,axis = 1,inplace = True)\n",
    "\n",
    "train_ft.shape\n",
    "train_ft.rename(columns={'가격.1':'가격'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff1d0178-4c0c-45e3-b38c-3148fdafd560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "220b72d9-4653-41e3-aa3c-33f588ac8c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model_name=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e212b1eb-acfb-41a5-80d1-9433ca6ff04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = train_ft['리뷰']\n",
    "target=train_ft[['색감', '핏', '재질', '퀄리티', '제품상태', '가격', '두께']]\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2869b9e9-3832-4573-8e11-22996a36fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {-1: 0, 0: 1, 1: 2}\n",
    "\n",
    "target_train = target_train.replace(mapping)\n",
    "target_test = target_test.replace(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d9d5d4e-8b69-4a40-8cfc-aa6f17d82d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arr = data_train.to_numpy()\n",
    "test_arr = target_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30b8602e-897f-4ca3-af58-9f57880c0a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': {'input_ids': tensor([[  101,  9801, 30873,  ...,     0,     0,     0],\n",
       "         [  101, 10003, 47869,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]])},\n",
       " 'y': tensor([[2, 2, 1, 1, 1, 1, 1],\n",
       "         [1, 2, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ReviewDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenizer, x, y=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {}\n",
    "        item[\"x\"] = self.get_tokenizer(self.x[idx])\n",
    "        if self.y is not None:\n",
    "            item[\"y\"] = torch.tensor(self.y[idx])\n",
    "        return item\n",
    "    def get_tokenizer(self, text):\n",
    "        x = self.tokenizer(text, padding=\"max_length\", truncation=True)\n",
    "        for k, v in x.items():\n",
    "            x[k] = torch.tensor(v)\n",
    "        return x\n",
    "\n",
    "dt = ReviewDataset(tokenizer, train_arr, test_arr)\n",
    "dl = torch.utils.data.DataLoader(dt, batch_size=2, shuffle=False)\n",
    "batch = next(iter(dl))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78f0107a-0981-4740-8756-9e820fe73289",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, model_name, num_features=7):\n",
    "        super().__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.fc_out = torch.nn.Linear(self.model.config.hidden_size, 3)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(**x)\n",
    "        output = self.fc_out(output[0])   #1d cnn하던가 ,gru?, (2,512,3)\n",
    "        # 정답 쉐이프와 맞게 레이어 추가\n",
    "        return torch.sum(output,dim=2)    # 회귀로\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30cb652b-fa0a-420a-b761-05d2302f5c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4920, -0.4917, -0.4111,  ..., -0.4676, -0.4563, -0.4434],\n",
       "         [-0.3054, -0.3157, -0.2826,  ..., -0.2970, -0.2443, -0.2635]],\n",
       "        grad_fn=<SumBackward1>),\n",
       " tensor([[2, 1, 2, 1, 1, 1, 1],\n",
       "         [1, 0, 1, 1, 1, 1, 0]]),\n",
       " torch.Size([2, 512]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net(model_name)\n",
    "pred=model(batch[\"x\"])\n",
    "pred,batch['y'],pred.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42642140-948d-43b3-9675-a4b0006c3aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, model_name, num_features=7):\n",
    "        super().__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.fc_out = torch.nn.Linear(self.model.config.hidden_size, 3)\n",
    "        self.fc_layers = torch.nn.ModuleList([self.fc_out for _ in range(num_features)]) # 배치 7 3\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for fc in self.fc_layers:\n",
    "            output = self.model(**x)\n",
    "            output = fc(output[0][:, 0])\n",
    "            outputs.append(output.unsqueeze(1)) \n",
    "        return torch.cat(outputs, dim=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b608b0a-c289-4d72-8a31-1db020c3506c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0974, 0.2472, 0.4966],\n",
       "          [0.0974, 0.2472, 0.4966],\n",
       "          [0.0974, 0.2472, 0.4966],\n",
       "          [0.0974, 0.2472, 0.4966],\n",
       "          [0.0974, 0.2472, 0.4966],\n",
       "          [0.0974, 0.2472, 0.4966],\n",
       "          [0.0974, 0.2472, 0.4966]],\n",
       " \n",
       "         [[0.1234, 0.2891, 0.5211],\n",
       "          [0.1234, 0.2891, 0.5211],\n",
       "          [0.1234, 0.2891, 0.5211],\n",
       "          [0.1234, 0.2891, 0.5211],\n",
       "          [0.1234, 0.2891, 0.5211],\n",
       "          [0.1234, 0.2891, 0.5211],\n",
       "          [0.1234, 0.2891, 0.5211]]], grad_fn=<CatBackward0>),\n",
       " tensor([[2, 2, 1, 1, 1, 1, 1],\n",
       "         [1, 2, 1, 1, 1, 1, 1]]),\n",
       " torch.Size([2, 7, 3]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net(model_name)\n",
    "pred=model(batch[\"x\"])\n",
    "pred,batch['y'],pred.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ac21f52-823a-4735-bff7-e579d8cdbd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, device):\n",
    "    epoch_loss = 0\n",
    "    model.train() # 학습 모드\n",
    "    for batch in tqdm(dataloader):\n",
    "        pred = model( batch[\"x\"].to(device) )\n",
    "        loss = loss_fn(pred.reshape(-1,3), batch['y'].flatten().to(device))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(dataloader)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d73e5d2f-97e5-42c3-9651-84078ae0aae7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loss_fn = torch.nn.CrossEntropyLoss()\n",
    "# dt = ReviewDataset(tokenizer, train_arr, test_arr)\n",
    "# dataloader = torch.utils.data.DataLoader(dt, batch_size=2, shuffle=False)\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# train_loop(dataloader, model, loss_fn, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c464dadb-4f4b-4150-987c-fe0e15befe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_loop(dataloader, model, loss_fn, device):\n",
    "    epoch_loss = 0\n",
    "    pred_list = []\n",
    "    act_func = torch.nn.Softmax(dim=2)\n",
    "    model.eval() # 평가 모드\n",
    "    for batch in tqdm(dataloader):\n",
    "        pred = model( batch[\"x\"].to(device) )\n",
    "        if batch.get(\"y\") is not None:\n",
    "            loss = loss_fn(pred.reshape(-1,3), batch['y'].flatten().to(device))\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        pred = act_func(pred) # logit 값을 확률로 변환\n",
    "        pred = pred.to(\"cpu\").numpy() # cpu 이동후 ndarray 로변환\n",
    "        pred_list.append(pred)\n",
    "\n",
    "    epoch_loss /= len(dataloader)\n",
    "    pred = np.concatenate(pred_list)\n",
    "    \n",
    "    return epoch_loss, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "353a0ed7-4b22-49a0-af5d-e7190c353a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = torch.nn.CrossEntropyLoss()\n",
    "# dt = ReviewDataset(tokenizer, train_arr, test_arr)\n",
    "# dataloader = torch.utils.data.DataLoader(dt, batch_size=2, shuffle=False)\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# test_loop(dataloader, model, loss_fn, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ea6c942-f304-4652-9138-b80251727587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "n_splits = 5\n",
    "\n",
    "cv = StratifiedKFold(n_splits, shuffle=True, random_state=SEED)\n",
    "cv = KFold(n_splits, shuffle=True, random_state=SEED)\n",
    "\n",
    "batch_size = 2 # 배치 사이즈\n",
    "loss_fn = torch.nn.CrossEntropyLoss() # 손실 객체\n",
    "epochs = 100 # 최대 가능한 에폭수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "263c09bb-bf09-4efb-ad96-eb165a8151c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt = ReviewDataset(tokenizer, train_arr, test_arr)\n",
    "# dl = torch.utils.data.DataLoader(dt, batch_size=2, shuffle=False)\n",
    "# batch = next(iter(dl))\n",
    "# batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7327353-9faf-45ba-82f6-c681d92a21d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e9db5d3ea164a268832bc5bba2374df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2302 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# 조기 종료 조건을 주기 위한 변수\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 23\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     valid_loss, pred \u001b[38;5;241m=\u001b[39m test_loop(valid_dl, model, loss_fn, device)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(pred)\n",
      "Cell \u001b[0;32mIn[27], line 6\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer, device)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader):\n\u001b[1;32m      5\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model( batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device) )\n\u001b[0;32m----> 6\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(pred\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m), \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      8\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      9\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "is_holdout = True\n",
    "reset_seeds(SEED) # 재현을 위해 시드고정\n",
    "best_score_list = []\n",
    "\n",
    "for i, (tri, vai) in enumerate(cv.split(data_train,target_train)):\n",
    "    # 학습용 데이터로더 객체\n",
    "    train_dt = ReviewDataset(tokenizer,train_arr[tri], test_arr[tri])\n",
    "    train_dl = torch.utils.data.DataLoader(train_dt, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # 검증용 데이터로더 객체\n",
    "    valid_dt = ReviewDataset(tokenizer,train_arr[vai], test_arr[vai])\n",
    "    valid_dl = torch.utils.data.DataLoader(valid_dt, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # 모델 객체와 옵티마이저 객체 생성\n",
    "    model = Net(model_name).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "    best_score = 0  # 현재 최고 점수\n",
    "    patience = 0  # 조기 종료 조건을 주기 위한 변수\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_loop(train_dl, model, loss_fn, optimizer, device)\n",
    "        valid_loss, pred = test_loop(valid_dl, model, loss_fn, device)\n",
    "\n",
    "        print(pred)\n",
    "        print(pred.shape)\n",
    "        print(test_arr[vai])\n",
    "        print(test_arr[vai].shape)\n",
    "        \n",
    "        pred = np.argmax(pred, axis=2)  # 다중 클래스 분류 문제로 변환\n",
    "        #pred = pred.flatten()  # 2차원 배열을 1차원 배열로 변환\n",
    "        #test_labels = test_arr[vai].flatten()  # 다중 클래스 분류 문제에 맞게 타겟 데이터를 평탄화\n",
    "\n",
    "        print(f'변형후 :{pred},{pred.shape},{test_arr[vai].shape}')\n",
    "        score = f1_score(pred, test_arr[vai], average='macro')  # F1 점수 계산\n",
    "        \n",
    "        print(f\"Epoch {epoch}: Train Loss: {train_loss}, Valid Loss: {valid_loss}, F1 Score: {score}\")\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score  # 최고 점수 업데이트\n",
    "            patience = 0\n",
    "            torch.save(model.state_dict(), f\"model_{i}.pth\")  # 최고 점수 모델 가중치 저장\n",
    "\n",
    "        patience += 1\n",
    "        if patience == 5:\n",
    "            break\n",
    "\n",
    "    print(f\"{i}번째 폴드 최고 F1 점수: {best_score}\")\n",
    "    best_score_list.append(best_score)\n",
    "\n",
    "    if is_holdout:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f740e310-ae6b-4b04-98ea-201cb556fb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 샘플 개수, 문장 길이, 클래스 개수\n",
    "num_samples = 5\n",
    "sentence_length = 7\n",
    "num_classes = 3\n",
    "\n",
    "# 샘플을 담을 빈 배열 생성\n",
    "data = np.empty((num_samples, sentence_length, num_classes))\n",
    "\n",
    "# 각 샘플에 대해 클래스 할당\n",
    "for i in range(num_samples):\n",
    "    for j in range(sentence_length):\n",
    "        # 각 샘플에 따라 클래스 할당\n",
    "        data[i, j] = i + 1\n",
    "\n",
    "print(data)\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790623ca-efb1-4ac2-a5da-79242489eda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "is_holdout = True\n",
    "reset_seeds(SEED) # 재현을 위해 시드고정\n",
    "best_score_list = []\n",
    "\n",
    "for i, (tri, vai) in enumerate(cv.split(data_train,target_train)):\n",
    "    # 학습용 데이터로더 객체\n",
    "    train_dt = ReviewDataset(tokenizer,train_arr[tri], test_arr[tri])\n",
    "    train_dl = torch.utils.data.DataLoader(train_dt, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # 검증용 데이터로더 객체\n",
    "    valid_dt = ReviewDataset(tokenizer,train_arr[vai], test_arr[vai])\n",
    "    valid_dl = torch.utils.data.DataLoader(valid_dt, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # 모델 객체와 옵티마이저 객체 생성\n",
    "    model = Net(model_name).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "    best_score = 0  # 현재 최고 점수\n",
    "    patience = 0  # 조기 종료 조건을 주기 위한 변수\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_loop(train_dl, model, loss_fn, optimizer, device)\n",
    "        valid_loss, pred = test_loop(valid_dl, model, loss_fn, device)\n",
    "\n",
    "        print(pred)\n",
    "        print(pred.shape)\n",
    "        print(test_arr[vai])\n",
    "        print(test_arr[vai].shape)\n",
    "        \n",
    "        pred = np.argmax(pred, axis=2)  # 다중 클래스 분류 문제로 변환\n",
    "        scores = []\n",
    "        for j in range(pred.shape[1]):\n",
    "            score = f1_score(pred[:, j], test_arr[vai][:, j], average='macro')\n",
    "            scores.append(score)\n",
    "        mean_f1_score = np.mean(scores)\n",
    "        \n",
    "        print(f\"Epoch {epoch}: Train Loss: {train_loss}, Valid Loss: {valid_loss}, Mean F1 Score: {mean_f1_score}\")\n",
    "\n",
    "        if mean_f1_score > best_score:\n",
    "            best_score = mean_f1_score  # 최고 점수 업데이트\n",
    "            patience = 0\n",
    "            torch.save(model.state_dict(), f\"model_{i}.pth\")  # 최고 점수 모델 가중치 저장\n",
    "\n",
    "        patience += 1\n",
    "        if patience == 5:\n",
    "            break\n",
    "\n",
    "    print(f\"{i}번째 폴드 최고 평균 F1 점수: {best_score}\")\n",
    "    best_score_list.append(best_score)\n",
    "\n",
    "    if is_holdout:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9244d855-1137-4fe4-8409-e1b3e1cc1079",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed20264381384e79b160fcd02dc8e8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2302 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fd777a7128494fb981d695d38d5ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/576 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.09783443 0.69039667 0.21176893]\n",
      "  [0.09783443 0.69039667 0.21176893]\n",
      "  [0.09783443 0.69039667 0.21176893]\n",
      "  ...\n",
      "  [0.09783443 0.69039667 0.21176893]\n",
      "  [0.09783443 0.69039667 0.21176893]\n",
      "  [0.09783443 0.69039667 0.21176893]]\n",
      "\n",
      " [[0.14635247 0.7001803  0.15346727]\n",
      "  [0.14635247 0.7001803  0.15346727]\n",
      "  [0.14635247 0.7001803  0.15346727]\n",
      "  ...\n",
      "  [0.14635247 0.7001803  0.15346727]\n",
      "  [0.14635247 0.7001803  0.15346727]\n",
      "  [0.14635247 0.7001803  0.15346727]]\n",
      "\n",
      " [[0.1742544  0.7274243  0.09832121]\n",
      "  [0.1742544  0.7274243  0.09832121]\n",
      "  [0.1742544  0.7274243  0.09832121]\n",
      "  ...\n",
      "  [0.1742544  0.7274243  0.09832121]\n",
      "  [0.1742544  0.7274243  0.09832121]\n",
      "  [0.1742544  0.7274243  0.09832121]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.1832612  0.6759857  0.14075315]\n",
      "  [0.1832612  0.6759857  0.14075315]\n",
      "  [0.1832612  0.6759857  0.14075315]\n",
      "  ...\n",
      "  [0.1832612  0.6759857  0.14075315]\n",
      "  [0.1832612  0.6759857  0.14075315]\n",
      "  [0.1832612  0.6759857  0.14075315]]\n",
      "\n",
      " [[0.09601477 0.6497445  0.25424078]\n",
      "  [0.09601477 0.6497445  0.25424078]\n",
      "  [0.09601477 0.6497445  0.25424078]\n",
      "  ...\n",
      "  [0.09601477 0.6497445  0.25424078]\n",
      "  [0.09601477 0.6497445  0.25424078]\n",
      "  [0.09601477 0.6497445  0.25424078]]\n",
      "\n",
      " [[0.06176675 0.69698954 0.24124372]\n",
      "  [0.06176675 0.69698954 0.24124372]\n",
      "  [0.06176675 0.69698954 0.24124372]\n",
      "  ...\n",
      "  [0.06176675 0.69698954 0.24124372]\n",
      "  [0.06176675 0.69698954 0.24124372]\n",
      "  [0.06176675 0.69698954 0.24124372]]]\n",
      "(1151, 7, 3)\n",
      "[[1 0 1 ... 1 1 1]\n",
      " [1 0 0 ... 1 1 1]\n",
      " [1 1 0 ... 1 1 1]\n",
      " ...\n",
      " [2 0 1 ... 1 1 1]\n",
      " [2 1 1 ... 1 1 1]\n",
      " [1 2 2 ... 1 1 1]]\n",
      "(1151, 7)\n",
      "======\n",
      "0.2808781632311044\n",
      "======\n",
      "======\n",
      "0.2010517799352751\n",
      "======\n",
      "======\n",
      "0.2741687979539642\n",
      "======\n",
      "======\n",
      "0.27296049256028737\n",
      "======\n",
      "======\n",
      "0.31803725579282144\n",
      "======\n",
      "======\n",
      "0.315162620247366\n",
      "======\n",
      "======\n",
      "0.2993457794798149\n",
      "======\n",
      "[0.2808781632311044, 0.2010517799352751, 0.2741687979539642, 0.27296049256028737, 0.31803725579282144, 0.315162620247366, 0.2993457794798149]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend(score)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(scores)\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mscores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n\u001b[1;32m     42\u001b[0m mean_f1_score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(scores)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(mean_f1_score)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "is_holdout = True\n",
    "reset_seeds(SEED) # 재현을 위해 시드고정\n",
    "best_score_list = []\n",
    "\n",
    "for i, (tri, vai) in enumerate(cv.split(data_train,target_train)):\n",
    "    # 학습용 데이터로더 객체\n",
    "    train_dt = ReviewDataset(tokenizer,train_arr[tri], test_arr[tri])\n",
    "    train_dl = torch.utils.data.DataLoader(train_dt, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # 검증용 데이터로더 객체\n",
    "    valid_dt = ReviewDataset(tokenizer,train_arr[vai], test_arr[vai])\n",
    "    valid_dl = torch.utils.data.DataLoader(valid_dt, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # 모델 객체와 옵티마이저 객체 생성\n",
    "    model = Net(model_name).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "    best_score = 0  # 현재 최고 점수\n",
    "    patience = 0  # 조기 종료 조건을 주기 위한 변수\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_loop(train_dl, model, loss_fn, optimizer, device)\n",
    "        valid_loss, pred = test_loop(valid_dl, model, loss_fn, device)\n",
    "\n",
    "        print(pred)\n",
    "        print(pred.shape)\n",
    "        print(test_arr[vai])\n",
    "        print(test_arr[vai].shape)\n",
    "        \n",
    "        pred = np.argmax(pred, axis=2)  \n",
    "        scores = []\n",
    "        for j in range(pred.shape[1]):\n",
    "            score = f1_score(test_arr[vai][:, j],pred[:, j], average='macro')\n",
    "            print('======')\n",
    "            print(f'{score}')\n",
    "            print('======')\n",
    "            scores.append(score)\n",
    "        \n",
    "        print(scores)\n",
    "        print(scores.shape)\n",
    "        mean_f1_score = np.mean(scores)\n",
    "\n",
    "        print(mean_f1_score)\n",
    "        print(mean_f1_score.shape)\n",
    "        \n",
    "        print(f\"Epoch {epoch}: Train Loss: {train_loss}, Valid Loss: {valid_loss}, Mean F1 Score: {mean_f1_score}\")\n",
    "        \n",
    "        if mean_f1_score > best_score:\n",
    "            best_score = mean_f1_score  # 최고 점수 업데이트\n",
    "            patience = 0\n",
    "            torch.save(model.state_dict(), f\"model_{i}.pth\")  # 최고 점수 모델 가중치 저장\n",
    "\n",
    "        patience += 1\n",
    "        if patience == 5:\n",
    "            break\n",
    "\n",
    "    print(f\"{i}번째 폴드 최고 평균 F1 점수: {best_score}\")\n",
    "    best_score_list.append(best_score)\n",
    "\n",
    "    if is_holdout:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7811d007-2ecf-4c19-9a72-ea8012b8ae20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
